{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krishil-Jayswal/Conformal-Prediction/blob/master/benchmark_scores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmarking"
      ],
      "metadata": {
        "id": "eFBrbuJMvEQF"
      },
      "id": "eFBrbuJMvEQF"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cab92a79",
      "metadata": {
        "id": "cab92a79"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(50)"
      ],
      "metadata": {
        "id": "hl7-4OoCveDK"
      },
      "id": "hl7-4OoCveDK",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tube Loss"
      ],
      "metadata": {
        "id": "eqS_Dn7DvydY"
      },
      "id": "eqS_Dn7DvydY"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_tube_model_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, q=0.90, r=0.5, delta=0, alpha=0.1, verbose=False):\n",
        "\n",
        "    # 1.\n",
        "    y_train = y_train.reshape(-1)\n",
        "    y_cal = y_cal.reshape(-1)\n",
        "    y_test = y_test.reshape(-1)\n",
        "\n",
        "    y_train_tb = np.stack((y_train, y_train), axis=1)\n",
        "    y_cal_tb = np.stack((y_cal, y_cal), axis=1)\n",
        "    y_test_tb = np.stack((y_test, y_test), axis=1)\n",
        "\n",
        "    def confidence_loss(y_true, y_pred):\n",
        "        y_true = y_true[:, 0]\n",
        "        f1 = y_pred[:, 0]  # Lower\n",
        "        f2 = y_pred[:, 1]  # Upper\n",
        "\n",
        "        c1 = (1 - q) * (f2 - y_true)\n",
        "        c2 = (1 - q) * (y_true - f1)\n",
        "        c3 = q * (f1 - y_true)\n",
        "        c4 = q * (y_true - f2)\n",
        "\n",
        "        loss_part1 = tf.where(y_true > r * (f1 + f2), c1, c2)\n",
        "        loss_part2 = tf.where(f1 > y_true, c3, c4)\n",
        "\n",
        "        final_loss = tf.where(tf.logical_and(y_true <= f2, y_true >= f1), loss_part1, loss_part2) + (delta * tf.abs(f1 - f2))\n",
        "        return tf.reduce_mean(final_loss)\n",
        "\n",
        "    # Build model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(200, input_dim=X_train.shape[1], activation='relu',\n",
        "                    kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.2)))\n",
        "    model.add(Dense(2, activation='linear',\n",
        "                    kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.3),\n",
        "                    bias_initializer=tf.keras.initializers.Constant(value=[-3, 3])))\n",
        "\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=0.02,\n",
        "        decay_steps=10000,\n",
        "        decay_rate=0.01)\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "    model.compile(loss=confidence_loss, optimizer=opt)\n",
        "\n",
        "    # Train model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train_tb, epochs=400, batch_size=40, verbose=0)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # Predict on calibration and test\n",
        "    y_cal_pred = model.predict(X_cal, verbose=0)\n",
        "    y_test_pred = model.predict(X_test, verbose=0)\n",
        "\n",
        "    q_lo_cal = y_cal_pred[:, 0]\n",
        "    q_hi_cal = y_cal_pred[:, 1]\n",
        "    q_lo_test = y_test_pred[:, 0]\n",
        "    q_hi_test = y_test_pred[:, 1]\n",
        "\n",
        "    # Conformal adjustment\n",
        "    scores = np.maximum(q_lo_cal - y_cal, y_cal - q_hi_cal)\n",
        "    q_hat = np.quantile(scores, 1 - alpha, method='higher')\n",
        "\n",
        "    lower_bound = q_lo_test - q_hat\n",
        "    upper_bound = q_hi_test + q_hat\n",
        "\n",
        "    # Evaluation\n",
        "    coverage = np.mean((y_test >= lower_bound) & (y_test <= upper_bound))\n",
        "    mpiw = np.mean(upper_bound - lower_bound)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Training time: {training_time:.2f} seconds\")\n",
        "        print(f\"PICP (conformal): {coverage:.4f}\")\n",
        "        print(f\"MPIW (conformal): {mpiw:.4f}\")\n",
        "\n",
        "    return training_time, coverage, mpiw"
      ],
      "metadata": {
        "id": "ODHHiym9pCSz"
      },
      "id": "ODHHiym9pCSz",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CQR"
      ],
      "metadata": {
        "id": "5dLKIz2Rv3z3"
      },
      "id": "5dLKIz2Rv3z3"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_two_model_cqr_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, q_low=0.1, q_high=0.9, alpha=0.1, verbose=False):\n",
        "\n",
        "    # 1.\n",
        "    y_train = y_train.reshape(-1)\n",
        "    y_test = y_test.reshape(-1)\n",
        "    y_cal = y_cal.reshape(-1)\n",
        "\n",
        "    def quantile_loss(q):\n",
        "        def loss(y_true, y_pred):\n",
        "            e = y_true - y_pred\n",
        "            return tf.reduce_mean(tf.maximum(q * e, (q - 1) * e))\n",
        "        return loss\n",
        "\n",
        "    def build_model(input_dim):\n",
        "        return Sequential([\n",
        "            Dense(200, input_dim=input_dim, activation='relu'),\n",
        "            Dense(1, activation='linear')\n",
        "        ])\n",
        "\n",
        "    # Separate optimizers for each model\n",
        "    opt_lower = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "    opt_upper = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "    model_lo = build_model(X_train.shape[1])\n",
        "    model_hi = build_model(X_train.shape[1])\n",
        "\n",
        "    model_lo.compile(loss=quantile_loss(q_low), optimizer=opt_lower)\n",
        "    model_hi.compile(loss=quantile_loss(q_high), optimizer=opt_upper)\n",
        "\n",
        "    # 2. Train both models\n",
        "    start_time = time.time()\n",
        "    model_lo.fit(X_train, y_train, epochs=400, batch_size=40, verbose=0)\n",
        "    model_hi.fit(X_train, y_train, epochs=400, batch_size=40, verbose=0)\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    # 3. Predict quantiles on calibration and test sets\n",
        "    def predict_quantiles(model, X):\n",
        "        return model.predict(X, verbose=0).reshape(-1)\n",
        "\n",
        "    q_lo_cal = predict_quantiles(model_lo, X_cal)\n",
        "    q_hi_cal = predict_quantiles(model_hi, X_cal)\n",
        "    q_lo_test = predict_quantiles(model_lo, X_test)\n",
        "    q_hi_test = predict_quantiles(model_hi, X_test)\n",
        "\n",
        "    # 4. Conformal adjustment\n",
        "    scores = np.maximum(q_lo_cal - y_cal, y_cal - q_hi_cal)\n",
        "    q_hat = np.quantile(scores, 1 - alpha, method='higher')\n",
        "\n",
        "    lower_bound = q_lo_test - q_hat\n",
        "    upper_bound = q_hi_test + q_hat\n",
        "\n",
        "    # 5. Evaluation metrics\n",
        "    coverage = np.mean((y_test >= lower_bound) & (y_test <= upper_bound))\n",
        "    mpiw = np.mean(upper_bound - lower_bound)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Training time: {training_time:.2f} seconds\")\n",
        "        print(f\"PICP (conformal): {coverage:.4f}\")\n",
        "        print(f\"MPIW (conformal): {mpiw:.4f}\")\n",
        "\n",
        "    return training_time, coverage, mpiw"
      ],
      "metadata": {
        "id": "YUtqGXu8oDOf"
      },
      "id": "YUtqGXu8oDOf",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Concrete Dataset"
      ],
      "metadata": {
        "id": "TdFse2ESwGUo"
      },
      "id": "TdFse2ESwGUo"
    },
    {
      "cell_type": "code",
      "source": [
        "concrete_df = pd.read_csv(\"https://raw.githubusercontent.com/Krishil-Jayswal/Conformal-Prediction/refs/heads/master/datasets/Concrete_Data.csv\")"
      ],
      "metadata": {
        "id": "4lbU9zMlvaWy"
      },
      "id": "4lbU9zMlvaWy",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a42bbf9a",
      "metadata": {
        "id": "a42bbf9a"
      },
      "outputs": [],
      "source": [
        "X = concrete_df.iloc[:, :-1]\n",
        "y = concrete_df.iloc[:, -1:].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train, cal, test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_cal, X_test, y_cal, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "e7IbRTtxvPGJ"
      },
      "id": "e7IbRTtxvPGJ",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tubeloss Scores:\")\n",
        "training_time, picp, mpiw = train_tube_model_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, verbose=True)\n",
        "print(\"CQR Scores:\")\n",
        "training_time, picp, mpiw = train_two_model_cqr_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, q_low=0.05, q_high=0.95, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GR7_fjWwVvr",
        "outputId": "d9844450-f6a0-4576-9cef-5730f976090c"
      },
      "id": "3GR7_fjWwVvr",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tubeloss Scores:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 47.83 seconds\n",
            "PICP (conformal): 0.8835\n",
            "MPIW (conformal): 19.6368\n",
            "CQR Scores:\n",
            "Training time: 82.26 seconds\n",
            "PICP (conformal): 0.8544\n",
            "MPIW (conformal): 15.5231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Bike Dataset"
      ],
      "metadata": {
        "id": "ksObOfecw9Ui"
      },
      "id": "ksObOfecw9Ui"
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/Krishil-Jayswal/Conformal-Prediction/refs/heads/master/datasets/bike_train.csv\")\n",
        "\n",
        "# # seperating season as per values. this is bcoz this will enhance features.\n",
        "season=pd.get_dummies(df['season'],prefix='season')\n",
        "df=pd.concat([df,season],axis=1)\n",
        "\n",
        "# # # same for weather. this is bcoz this will enhance features.\n",
        "weather=pd.get_dummies(df['weather'],prefix='weather')\n",
        "df=pd.concat([df,weather],axis=1)\n",
        "\n",
        "# # # now can drop weather and season.\n",
        "df.drop(['season','weather'],inplace=True,axis=1)\n",
        "df.head()\n",
        "\n",
        "df[\"hour\"] = [t.hour for t in pd.DatetimeIndex(df.datetime)]\n",
        "df[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(df.datetime)]\n",
        "df[\"month\"] = [t.month for t in pd.DatetimeIndex(df.datetime)]\n",
        "df['year'] = [t.year for t in pd.DatetimeIndex(df.datetime)]\n",
        "df['year'] = df['year'].map({2011:0, 2012:1})\n",
        "\n",
        "df.drop('datetime',axis=1,inplace=True)\n",
        "df.drop(['casual','registered'],axis=1,inplace=True)\n",
        "df.columns.to_series().groupby(df.dtypes).groups\n",
        "X = df.drop('count', axis=1).astype(float).values\n",
        "y = df['count'].values"
      ],
      "metadata": {
        "id": "nETQ2rzzxBvL"
      },
      "id": "nETQ2rzzxBvL",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train, cal, test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_cal, X_test, y_cal, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "w21UcDFTxd3r"
      },
      "id": "w21UcDFTxd3r",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tubeloss Scores:\")\n",
        "training_time, picp, mpiw = train_tube_model_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, verbose=True)\n",
        "print(\"CQR Scores:\")\n",
        "training_time, picp, mpiw = train_two_model_cqr_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, q_low=0.05, q_high=0.95, verbose=True)"
      ],
      "metadata": {
        "id": "y1VE8hHkxhc5"
      },
      "id": "y1VE8hHkxhc5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Star Dataset"
      ],
      "metadata": {
        "id": "Ikbw93BRxliG"
      },
      "id": "Ikbw93BRxliG"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Krishil-Jayswal/Conformal-Prediction/refs/heads/master/datasets/STAR.csv\")\n",
        "df.loc[df['gender'] == 'female', 'gender'] = 0\n",
        "df.loc[df['gender'] == 'male', 'gender'] = 1\n",
        "\n",
        "df.loc[df['ethnicity'] == 'cauc', 'ethnicity'] = 0\n",
        "df.loc[df['ethnicity'] == 'afam', 'ethnicity'] = 1\n",
        "df.loc[df['ethnicity'] == 'asian', 'ethnicity'] = 2\n",
        "df.loc[df['ethnicity'] == 'hispanic', 'ethnicity'] = 3\n",
        "df.loc[df['ethnicity'] == 'amindian', 'ethnicity'] = 4\n",
        "df.loc[df['ethnicity'] == 'other', 'ethnicity'] = 5\n",
        "\n",
        "df.loc[df['stark'] == 'regular', 'stark'] = 0\n",
        "df.loc[df['stark'] == 'small', 'stark'] = 1\n",
        "df.loc[df['stark'] == 'regular+aide', 'stark'] = 2\n",
        "\n",
        "df.loc[df['star1'] == 'regular', 'star1'] = 0\n",
        "df.loc[df['star1'] == 'small', 'star1'] = 1\n",
        "df.loc[df['star1'] == 'regular+aide', 'star1'] = 2\n",
        "\n",
        "df.loc[df['star2'] == 'regular', 'star2'] = 0\n",
        "df.loc[df['star2'] == 'small', 'star2'] = 1\n",
        "df.loc[df['star2'] == 'regular+aide', 'star2'] = 2\n",
        "\n",
        "df.loc[df['star3'] == 'regular', 'star3'] = 0\n",
        "df.loc[df['star3'] == 'small', 'star3'] = 1\n",
        "df.loc[df['star3'] == 'regular+aide', 'star3'] = 2\n",
        "\n",
        "df.loc[df['lunchk'] == 'free', 'lunchk'] = 0\n",
        "df.loc[df['lunchk'] == 'non-free', 'lunchk'] = 1\n",
        "\n",
        "df.loc[df['lunch1'] == 'free', 'lunch1'] = 0\n",
        "df.loc[df['lunch1'] == 'non-free', 'lunch1'] = 1\n",
        "\n",
        "df.loc[df['lunch2'] == 'free', 'lunch2'] = 0\n",
        "df.loc[df['lunch2'] == 'non-free', 'lunch2'] = 1\n",
        "\n",
        "df.loc[df['lunch3'] == 'free', 'lunch3'] = 0\n",
        "df.loc[df['lunch3'] == 'non-free', 'lunch3'] = 1\n",
        "\n",
        "df.loc[df['schoolk'] == 'inner-city', 'schoolk'] = 0\n",
        "df.loc[df['schoolk'] == 'suburban', 'schoolk'] = 1\n",
        "df.loc[df['schoolk'] == 'rural', 'schoolk'] = 2\n",
        "df.loc[df['schoolk'] == 'urban', 'schoolk'] = 3\n",
        "\n",
        "df.loc[df['school1'] == 'inner-city', 'school1'] = 0\n",
        "df.loc[df['school1'] == 'suburban', 'school1'] = 1\n",
        "df.loc[df['school1'] == 'rural', 'school1'] = 2\n",
        "df.loc[df['school1'] == 'urban', 'school1'] = 3\n",
        "\n",
        "df.loc[df['school2'] == 'inner-city', 'school2'] = 0\n",
        "df.loc[df['school2'] == 'suburban', 'school2'] = 1\n",
        "df.loc[df['school2'] == 'rural', 'school2'] = 2\n",
        "df.loc[df['school2'] == 'urban', 'school2'] = 3\n",
        "\n",
        "df.loc[df['school3'] == 'inner-city', 'school3'] = 0\n",
        "df.loc[df['school3'] == 'suburban', 'school3'] = 1\n",
        "df.loc[df['school3'] == 'rural', 'school3'] = 2\n",
        "df.loc[df['school3'] == 'urban', 'school3'] = 3\n",
        "\n",
        "df.loc[df['degreek'] == 'bachelor', 'degreek'] = 0\n",
        "df.loc[df['degreek'] == 'master', 'degreek'] = 1\n",
        "df.loc[df['degreek'] == 'specialist', 'degreek'] = 2\n",
        "df.loc[df['degreek'] == 'master+', 'degreek'] = 3\n",
        "\n",
        "df.loc[df['degree1'] == 'bachelor', 'degree1'] = 0\n",
        "df.loc[df['degree1'] == 'master', 'degree1'] = 1\n",
        "df.loc[df['degree1'] == 'specialist', 'degree1'] = 2\n",
        "df.loc[df['degree1'] == 'phd', 'degree1'] = 3\n",
        "\n",
        "df.loc[df['degree2'] == 'bachelor', 'degree2'] = 0\n",
        "df.loc[df['degree2'] == 'master', 'degree2'] = 1\n",
        "df.loc[df['degree2'] == 'specialist', 'degree2'] = 2\n",
        "df.loc[df['degree2'] == 'phd', 'degree2'] = 3\n",
        "\n",
        "df.loc[df['degree3'] == 'bachelor', 'degree3'] = 0\n",
        "df.loc[df['degree3'] == 'master', 'degree3'] = 1\n",
        "df.loc[df['degree3'] == 'specialist', 'degree3'] = 2\n",
        "df.loc[df['degree3'] == 'phd', 'degree3'] = 3\n",
        "\n",
        "df.loc[df['ladderk'] == 'level1', 'ladderk'] = 0\n",
        "df.loc[df['ladderk'] == 'level2', 'ladderk'] = 1\n",
        "df.loc[df['ladderk'] == 'level3', 'ladderk'] = 2\n",
        "df.loc[df['ladderk'] == 'apprentice', 'ladderk'] = 3\n",
        "df.loc[df['ladderk'] == 'probation', 'ladderk'] = 4\n",
        "df.loc[df['ladderk'] == 'pending', 'ladderk'] = 5\n",
        "df.loc[df['ladderk'] == 'notladder', 'ladderk'] = 6\n",
        "\n",
        "\n",
        "df.loc[df['ladder1'] == 'level1', 'ladder1'] = 0\n",
        "df.loc[df['ladder1'] == 'level2', 'ladder1'] = 1\n",
        "df.loc[df['ladder1'] == 'level3', 'ladder1'] = 2\n",
        "df.loc[df['ladder1'] == 'apprentice', 'ladder1'] = 3\n",
        "df.loc[df['ladder1'] == 'probation', 'ladder1'] = 4\n",
        "df.loc[df['ladder1'] == 'noladder', 'ladder1'] = 5\n",
        "df.loc[df['ladder1'] == 'notladder', 'ladder1'] = 6\n",
        "\n",
        "df.loc[df['ladder2'] == 'level1', 'ladder2'] = 0\n",
        "df.loc[df['ladder2'] == 'level2', 'ladder2'] = 1\n",
        "df.loc[df['ladder2'] == 'level3', 'ladder2'] = 2\n",
        "df.loc[df['ladder2'] == 'apprentice', 'ladder2'] = 3\n",
        "df.loc[df['ladder2'] == 'probation', 'ladder2'] = 4\n",
        "df.loc[df['ladder2'] == 'noladder', 'ladder2'] = 5\n",
        "df.loc[df['ladder2'] == 'notladder', 'ladder2'] = 6\n",
        "\n",
        "df.loc[df['ladder3'] == 'level1', 'ladder3'] = 0\n",
        "df.loc[df['ladder3'] == 'level2', 'ladder3'] = 1\n",
        "df.loc[df['ladder3'] == 'level3', 'ladder3'] = 2\n",
        "df.loc[df['ladder3'] == 'apprentice', 'ladder3'] = 3\n",
        "df.loc[df['ladder3'] == 'probation', 'ladder3'] = 4\n",
        "df.loc[df['ladder3'] == 'noladder', 'ladder3'] = 5\n",
        "df.loc[df['ladder3'] == 'notladder', 'ladder3'] = 6\n",
        "\n",
        "df.loc[df['tethnicityk'] == 'cauc', 'tethnicityk'] = 0\n",
        "df.loc[df['tethnicityk'] == 'afam', 'tethnicityk'] = 1\n",
        "\n",
        "df.loc[df['tethnicity1'] == 'cauc', 'tethnicity1'] = 0\n",
        "df.loc[df['tethnicity1'] == 'afam', 'tethnicity1'] = 1\n",
        "\n",
        "df.loc[df['tethnicity2'] == 'cauc', 'tethnicity2'] = 0\n",
        "df.loc[df['tethnicity2'] == 'afam', 'tethnicity2'] = 1\n",
        "\n",
        "df.loc[df['tethnicity3'] == 'cauc', 'tethnicity3'] = 0\n",
        "df.loc[df['tethnicity3'] == 'afam', 'tethnicity3'] = 1\n",
        "df.loc[df['tethnicity3'] == 'asian', 'tethnicity3'] = 2\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "grade = df[\"readk\"] + df[\"read1\"] + df[\"read2\"] + df[\"read3\"]\n",
        "grade += df[\"mathk\"] + df[\"math1\"] + df[\"math2\"] + df[\"math3\"]\n",
        "\n",
        "\n",
        "names = df.columns\n",
        "target_names = names[8:16]\n",
        "data_names = np.concatenate((names[0:8],names[17:]))\n",
        "X = df.loc[:, data_names].values\n",
        "y = grade.values"
      ],
      "metadata": {
        "id": "flnTsArlxoRw"
      },
      "id": "flnTsArlxoRw",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train, cal, test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_cal, X_test, y_cal, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "MKjt9BHoxzFD"
      },
      "id": "MKjt9BHoxzFD",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tubeloss Scores:\")\n",
        "training_time, picp, mpiw = train_tube_model_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, verbose=True)\n",
        "print(\"CQR Scores:\")\n",
        "training_time, picp, mpiw = train_two_model_cqr_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, q_low=0.05, q_high=0.95, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgCUDDtfx5bY",
        "outputId": "d3954941-e593-4768-895e-fba20f2e8471"
      },
      "id": "sgCUDDtfx5bY",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tubeloss Scores:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 56.13 seconds\n",
            "PICP (conformal): 0.9076\n",
            "MPIW (conformal): 2042.3408\n",
            "CQR Scores:\n",
            "Training time: 109.63 seconds\n",
            "PICP (conformal): 0.9215\n",
            "MPIW (conformal): 997.5884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Community Dataset"
      ],
      "metadata": {
        "id": "-WfA4mmpy7oB"
      },
      "id": "-WfA4mmpy7oB"
    },
    {
      "cell_type": "code",
      "source": [
        "attrib = pd.read_csv(\"https://raw.githubusercontent.com/Krishil-Jayswal/Conformal-Prediction/refs/heads/master/datasets/communities_attributes.csv\", delim_whitespace = True)\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/Krishil-Jayswal/Conformal-Prediction/refs/heads/master/datasets/communities.data\", names = attrib['attributes'])\n",
        "data = data.drop(columns=['state','county',\n",
        "                'community','communityname',\n",
        "                'fold'], axis=1)\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Convert '?' to NaN\n",
        "data = data.replace('?', np.nan).astype(float)\n",
        "\n",
        "# Impute 'OtherPerCap' with mean\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "data[['OtherPerCap']] = imputer.fit_transform(data[['OtherPerCap']])\n",
        "\n",
        "# Drop any remaining columns with NaN values\n",
        "data = data.dropna(axis=1)\n",
        "\n",
        "# Split into features and target\n",
        "X = data.iloc[:, 0:100].values\n",
        "y = data.iloc[:, 100].values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9blpEI2y7W3",
        "outputId": "3d95e79c-7bda-4f9d-dee3-e0d2cc7f41f3"
      },
      "id": "B9blpEI2y7W3",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-7a63b1c230cf>:1: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  attrib = pd.read_csv(\"https://raw.githubusercontent.com/Krishil-Jayswal/Conformal-Prediction/refs/heads/master/datasets/communities_attributes.csv\", delim_whitespace = True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train, cal, test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_cal, X_test, y_cal, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "aOgLmBL81FSe"
      },
      "id": "aOgLmBL81FSe",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tubeloss Scores:\")\n",
        "training_time, picp, mpiw = train_tube_model_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, verbose=True)\n",
        "print(\"CQR Scores:\")\n",
        "training_time, picp, mpiw = train_two_model_cqr_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, q_low=0.05, q_high=0.95, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0TDaHh01G9y",
        "outputId": "bb9768d0-af0d-4e42-b607-349440e898f9"
      },
      "id": "F0TDaHh01G9y",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tubeloss Scores:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 53.23 seconds\n",
            "PICP (conformal): 0.8997\n",
            "MPIW (conformal): 2.8906\n",
            "CQR Scores:\n",
            "Training time: 100.79 seconds\n",
            "PICP (conformal): 0.8722\n",
            "MPIW (conformal): 0.3682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Facebook Dataset"
      ],
      "metadata": {
        "id": "I5OhEU743Qi2"
      },
      "id": "I5OhEU743Qi2"
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Krishil-Jayswal/Conformal-Prediction/refs/heads/master/datasets/facebook_v1.csv\")\n",
        "X = df.iloc[:,0:53].values\n",
        "y = df.iloc[:,53].values"
      ],
      "metadata": {
        "id": "4WmjaLaH3BYS"
      },
      "id": "4WmjaLaH3BYS",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train, cal, test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_cal, X_test, y_cal, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "QNivEw743TlL"
      },
      "id": "QNivEw743TlL",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tubeloss Scores:\")\n",
        "training_time, picp, mpiw = train_tube_model_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, verbose=True)\n",
        "print(\"CQR Scores:\")\n",
        "training_time, picp, mpiw = train_two_model_cqr_conformal(X_train, y_train, X_cal, y_cal, X_test, y_test, q_low=0.05, q_high=0.95, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgTFtmCV3bLX",
        "outputId": "a2f914a6-ebed-4224-a002-879b1d1fe885"
      },
      "id": "EgTFtmCV3bLX",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tubeloss Scores:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 547.06 seconds\n",
            "PICP (conformal): 0.9034\n",
            "MPIW (conformal): 186.3247\n",
            "CQR Scores:\n",
            "Training time: 1051.28 seconds\n",
            "PICP (conformal): 0.9233\n",
            "MPIW (conformal): 15.9237\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eqS_Dn7DvydY",
        "5dLKIz2Rv3z3"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}